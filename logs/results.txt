Evaluation of 50:50:

user@Linux-Mint:~/thesis/win/go-strength-model$ python3 python/calc_performance.py csv7M/games_labels.csv -m T --fixed-prediction
Finished counting run of 10000 matchups between 312615 players.
Prediction accuracy: 6111/10000 (0.611), logp: -0.6931471805600546
Without zero-info matchups: 6111/10000 (0.611), logp: -0.6931471805600546
Only both-rated matchups: 6111/10000 (0.611), logp: -0.6931471805600546
user@Linux-Mint:~/thesis/win/go-strength-model$ python3 python/calc_performance.py csv7M/games_labels.csv -m V --fixed-prediction
Finished counting run of 5000 matchups between 312615 players.
Prediction accuracy: 3055/5000 (0.611), logp: -0.6931471805599917
Without zero-info matchups: 3055/5000 (0.611), logp: -0.6931471805599917
Only both-rated matchups: 3055/5000 (0.611), logp: -0.6931471805599917
user@Linux-Mint:~/thesis/win/go-strength-model$ python3 python/calc_performance.py csv7M/games_labels.csv -m E --fixed-prediction
Finished counting run of 5000 matchups between 312615 players.
Prediction accuracy: 3095/5000 (0.619), logp: -0.6931471805599917
Without zero-info matchups: 3095/5000 (0.619), logp: -0.6931471805599917
Only both-rated matchups: 3095/5000 (0.619), logp: -0.6931471805599917

Evaluation of Glicko-2:

user@Linux-Mint:~/thesis/win/go-strength-model$ python3 python/calc_performance.py csv7M/games_glicko.csv -m T
Finished counting run of 10000 matchups between 312615 players.
Prediction accuracy: 6977/10000 (0.698), logp: -0.5697387265182877
Without zero-info matchups: 6977/10000 (0.698), logp: -0.5697387265182877
Only both-rated matchups: 6977/10000 (0.698), logp: -0.5697387265182877
user@Linux-Mint:~/thesis/win/go-strength-model$ python3 python/calc_performance.py csv7M/games_glicko.csv -m V
Finished counting run of 5000 matchups between 312615 players.
Prediction accuracy: 3432/5000 (0.686), logp: -0.5831115614808127
Without zero-info matchups: 3432/5000 (0.686), logp: -0.5831115614808127
Only both-rated matchups: 3432/5000 (0.686), logp: -0.5831115614808127
user@Linux-Mint:~/thesis/win/go-strength-model$ python3 python/calc_performance.py csv7M/games_glicko.csv -m E
Finished counting run of 5000 matchups between 312615 players.
Prediction accuracy: 3456/5000 (0.691), logp: -0.5757609575555561
Without zero-info matchups: 3456/5000 (0.691), logp: -0.5757609575555561
Only both-rated matchups: 3456/5000 (0.691), logp: -0.5757609575555561

Evaluation of Future Glicko-2:

user@Linux-Mint:~/thesis/win/go-strength-model$ python3 python/calc_performance.py csv7M/games_labels.csv -m T
Finished counting run of 10000 matchups between 312615 players.
Prediction accuracy: 7562/10000 (0.756), logp: -0.5012060460649477
Without zero-info matchups: 7562/10000 (0.756), logp: -0.5012060460649477
Only both-rated matchups: 7562/10000 (0.756), logp: -0.5012060460649477
user@Linux-Mint:~/thesis/win/go-strength-model$ python3 python/calc_performance.py csv7M/games_labels.csv -m V
Finished counting run of 5000 matchups between 312615 players.
Prediction accuracy: 3732/5000 (0.746), logp: -0.5150358662621047
Without zero-info matchups: 3732/5000 (0.746), logp: -0.5150358662621047
Only both-rated matchups: 3732/5000 (0.746), logp: -0.5150358662621047
user@Linux-Mint:~/thesis/win/go-strength-model$ python3 python/calc_performance.py csv7M/games_labels.csv -m E
Finished counting run of 5000 matchups between 312615 players.
Prediction accuracy: 3772/5000 (0.754), logp: -0.5105815726636469
Without zero-info matchups: 3772/5000 (0.754), logp: -0.5105815726636469
Only both-rated matchups: 3772/5000 (0.754), logp: -0.5105815726636469

Evaluation of Stochastic Model:

user@Linux-Mint:~/thesis/win/go-strength-model$ python3 python/calc_performance.py csv7M/games_stochastic_t.csv -m T
Finished counting run of 10000 matchups between 10642 players.
Prediction accuracy: 6048/10000 (0.605), logp: -1.059106257569399
user@Linux-Mint:~/thesis/win/go-strength-model$ python3 python/calc_performance.py csv7M/games_stochastic_v.csv -m V
Finished counting run of 5000 matchups between 6288 players.
Prediction accuracy: 2962/5000 (0.592), logp: -1.092431268080814
user@Linux-Mint:~/thesis/win/go-strength-model$ python3 python/calc_performance.py csv7M/games_stochastic_e.csv -m E
Finished counting run of 5000 matchups between 6249 players.
Prediction accuracy: 2926/5000 (0.585), logp: -1.0617514042726237

Evaluation of Proof of Concept Model:

user@Linux-Mint:~/thesis/win/go-strength-model$ python3 python/calc_performance.py csv7M/games_pocmodel_t.csv -m T
Finished counting run of 10000 matchups between 10642 players.
Prediction accuracy: 4843/10000 (0.484), logp: -1.298705941928928
user@Linux-Mint:~/thesis/win/go-strength-model$ python3 python/calc_performance.py csv7M/games_pocmodel_v.csv -m V
Finished counting run of 5000 matchups between 6288 players.
Prediction accuracy: 2452/5000 (0.490), logp: -1.2715469021675325
user@Linux-Mint:~/thesis/win/go-strength-model$ python3 python/calc_performance.py csv7M/games_pocmodel_e.csv -m E
Finished counting run of 5000 matchups between 6249 players.
Prediction accuracy: 2486/5000 (0.497), logp: -1.2524562164012725

Evaluation of Full Model:

user@Linux-Mint:~/thesis/win/go-strength-model$ python3 python/calc_performance.py csv7M/games_model_t.csv -m T
Finished counting run of 10000 matchups between 10642 players.
Prediction accuracy: 6840/10000 (0.684), logp: -0.5850495146088135
user@Linux-Mint:~/thesis/win/go-strength-model$ python3 python/calc_performance.py csv7M/games_model_v.csv -m V
Finished counting run of 5000 matchups between 6288 players.
Prediction accuracy: 3405/5000 (0.681), logp: -0.5935229970841186
user@Linux-Mint:~/thesis/win/go-strength-model$ python3 python/calc_performance.py csv7M/games_model_e.csv -m E
Finished counting run of 5000 matchups between 6249 players.
Prediction accuracy: 3401/5000 (0.680), logp: -0.592018819758777

